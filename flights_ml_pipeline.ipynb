{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c2dc0f",
   "metadata": {},
   "source": [
    "## Building a Machine Learning Pipeline with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccf2d3",
   "metadata": {},
   "source": [
    "model to predict flight lateness based on various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327014e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import pyspark.ml.evaluation as evals\n",
    "import numpy as np\n",
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d57e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002389E292940>\n"
     ]
    }
   ],
   "source": [
    "# Creating SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Print spark\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe41243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='airports', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='planes', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Checking for existing tables in the catalog\n",
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce9d4a",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52467999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the flight data\n",
    "flight_df = spark.read.csv('flights_small.csv', header=True)\n",
    "\n",
    "# Reading in the airport data\n",
    "airports_df = spark.read.csv('airports.csv', header=True)\n",
    "\n",
    "# Reading in the plane data\n",
    "planes_df = spark.read.csv('planes.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be80abb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='airports', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='planes', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Creating temporary tables to support SQL queries\n",
    "flight_df.createOrReplaceTempView('flights')\n",
    "airports_df.createOrReplaceTempView('airports')\n",
    "planes_df.createOrReplaceTempView('planes')\n",
    "\n",
    "# Checking for existing tables in the catalog\n",
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b83e26",
   "metadata": {},
   "source": [
    "### Data Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd3510ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to select the first 10 rows of the flights table\n",
    "query = \"SELECT * FROM flights LIMIT 10\"\n",
    "\n",
    "# Get the first 10 rows of flights\n",
    "flights10 = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "flights10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77f4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# Function to return the shape of a DataFrame\n",
    "def dataframe_shape(df):\n",
    "  \"\"\"\n",
    "  This function takes a Spark DataFrame and returns its shape as a tuple\n",
    "  containing the number of rows and columns.\n",
    "\n",
    "  Args:\n",
    "      df: The DataFrame to get the shape of.\n",
    "\n",
    "  Returns:\n",
    "      str: the number of rows and columns.\n",
    "  \"\"\"\n",
    "  rows = df.count()\n",
    "  cols = len(df.columns)\n",
    "  shape = print(\"Shape of DataFrame: ({}, {})\".format(rows, cols))\n",
    "  return shape\n",
    "\n",
    "# Call the function with the flight data\n",
    "dataframe_shape(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d124d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of duplicates in a DataFrame\n",
    "def count_duplicates(df):\n",
    "  \"\"\"\n",
    "  This function counts the number of duplicate rows in a PySpark DataFrame.\n",
    "\n",
    "  Args:\n",
    "      df (pyspark.sql.DataFrame): The DataFrame to check for duplicates.\n",
    "\n",
    "  Returns:\n",
    "      str: The number of duplicate rows found.\n",
    "  \"\"\"\n",
    "  num_duplicates = df.count() - df.dropDuplicates().count()\n",
    "  dups = print(\"Number of duplicate rows:\", num_duplicates)\n",
    "  return dups\n",
    "\n",
    "# Checking the number of duplicate rows\n",
    "count_duplicates(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77127b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+------------+----+---+---+\n",
      "|faa|                name|       lat|         lon| alt| tz|dst|\n",
      "+---+--------------------+----------+------------+----+---+---+\n",
      "|04G|   Lansdowne Airport|41.1304722| -80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|32.4605722| -85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|41.9893408| -88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport| 41.431912| -74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|31.0744722| -81.4277778|  11| -4|  A|\n",
      "|0A9|Elizabethton Muni...|36.3712222| -82.1734167|1593| -4|  A|\n",
      "|0G6|Williams County A...|41.4673056| -84.5067778| 730| -5|  A|\n",
      "|0G7|Finger Lakes Regi...|42.8835647| -76.7812318| 492| -5|  A|\n",
      "|0P2|Shoestring Aviati...|39.7948244| -76.6471914|1000| -5|  U|\n",
      "|0S9|Jefferson County ...|48.0538086|-122.8106436| 108| -8|  A|\n",
      "+---+--------------------+----------+------------+----+---+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 rows of the airports DataFrame \n",
    "airports_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d19e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (1397, 7)\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the airports DataFrame\n",
    "dataframe_shape(airports_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a049458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the number of duplicate rows\n",
    "count_duplicates(airports_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ae28b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "|tailnum|year|                type|    manufacturer|   model|engines|seats|speed|   engine|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "| N102UW|1998|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N103US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N104UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N105UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N107US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N108UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N109UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N110UW|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N111US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N11206|2000|Fixed wing multi ...|          BOEING| 737-824|      2|  149|   NA|Turbo-fan|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 rows of the planes DataFrame\n",
    "planes_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a40b6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (2628, 9)\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the planes DataFrame\n",
    "dataframe_shape(planes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0be79fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the number of duplicate rows\n",
    "count_duplicates(planes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445a7e5",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4afcd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename year column for ease of joining\n",
    "planes_df = planes_df.withColumnRenamed(\"year\", \"plane_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1692ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the DataFrames\n",
    "model_data = flight_df.join(planes_df, on=\"tailnum\", how=\"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fc5cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the columns to integers\n",
    "model_data = model_data.withColumn(\"arr_delay\", model_data.arr_delay.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"air_time\", model_data.air_time.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"month\", model_data.month.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"plane_year\", model_data.plane_year.cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79847e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column plane_age\n",
    "model_data = model_data.withColumn(\"plane_age\", model_data.year - model_data.plane_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b05a459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create is_late\n",
    "model_data = model_data.withColumn(\"is_late\", model_data.arr_delay > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4bb1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert is_late to an integer\n",
    "model_data = model_data.withColumn(\"label\", model_data.is_late.cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "608c7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "model_data = model_data.filter(\"arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL and plane_year is not NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc93aaf",
   "metadata": {},
   "source": [
    "### Feature Engineering for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d87a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StringIndexer\n",
    "carr_indexer = StringIndexer(inputCol=\"carrier\", outputCol=\"carrier_index\")\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "carr_encoder = OneHotEncoder(inputCol=\"carrier_index\", outputCol=\"carrier_fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce84c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StringIndexer\n",
    "dest_indexer = StringIndexer(inputCol= \"dest\", outputCol= \"dest_index\")\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "dest_encoder = OneHotEncoder(inputCol= \"dest_index\", outputCol = \"dest_fact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f47b57",
   "metadata": {},
   "source": [
    "### Building the Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d936bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VectorAssembler\n",
    "vec_assembler = VectorAssembler(inputCols= [\"month\", \"air_time\", \"carrier_fact\", \"dest_fact\", \"plane_age\"], outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62653ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline\n",
    "flights_pipe = Pipeline(stages= [dest_indexer, \n",
    "                                 dest_encoder, \n",
    "                                 carr_indexer, \n",
    "                                 carr_encoder, \n",
    "                                 vec_assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae266f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "piped_data = flights_pipe.fit(model_data).transform(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc879a3",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "686c9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "training, test = piped_data.randomSplit([.6, .4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53d13bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression Estimator\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fef33e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "124ff9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Add the hyperparameter\n",
    "grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "# Build the grid\n",
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fca3e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CrossValidator\n",
    "cv = tune.CrossValidator(estimator=lr,\n",
    "               estimatorParamMaps=grid,\n",
    "               evaluator=evaluator\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d57d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# Extract the best model\n",
    "best_lr = models.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1642b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel: uid=LogisticRegression_ea8b8b83740b, numClasses=2, numFeatures=81\n"
     ]
    }
   ],
   "source": [
    "# Call lr.fit()\n",
    "best_lr = lr.fit(training)\n",
    "\n",
    "# Print best_lr\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb2eb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6884011858595228\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the test set\n",
    "test_results = best_lr.transform(test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(evaluator.evaluate(test_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
